# -*- coding: utf-8 -*-
"""Deeplabv3plus_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MtTTOlv1wYetEXZ3P2R7e5XKYPCKAgjV
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from keras import Model
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.layers import Input, Conv2D
from keras import backend as K
import tensorflow as tf
import keras
import os
import cv2
from tensorflow.python.keras.backend import set_session
from tensorflow.python.keras.models import load_model
from tensorflow.python.keras.optimizers import Adam, RMSprop
from model import Deeplabv3
from data_loader import image_segmentation_generator, verify_segmentation_dataset
K.set_session

opt = 'adam'
def load_model(backbone, classes, input_height, input_width):
  if backbone == "mobilenetv2":
    model = Deeplabv3(input_shape=(input_height, input_width,3), backbone=backbone, classes=classes)
  elif backbone=="xception":
    model = Deeplabv3(input_shape=(input_height, input_width,3), backbone=backbone, classes=classes)
  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
  model.summary()
  return model

# param
input_height = 512
input_width = 512
n_classes = 21
backbone = "mobilenetv2"


# model
model = load_model(backbone, n_classes, input_height, input_width)
model.load_weights('/content/drive/My Drive/deeplabv3_ep10.h5')
model_checkpoint = ModelCheckpoint('drive/My Drive/ep{epoch:03d}-loss{loss:.3f}.h5',
                                   monitor='loss', save_weights_only=True, save_best_only=True, period=1)
reduce_lr = ReduceLROnPlateau(factor=0.5, patience=2, min_lr=0.00001, verbose=1)
cks = [reduce_lr, model_checkpoint]

train_images = '/content/drive/My Drive/tmp/voc_jpeg/'
train_annotations = '/content/drive/My Drive/tmp/voc_anno/'
             
epochs=20
batch_size=1    
steps_per_epoch = 512
output_height = input_height
output_width = input_width 

train_gen = image_segmentation_generator(
    train_images, train_annotations,  batch_size,  n_classes,
    input_height, input_width, output_height, output_width, do_augment=False)

val_batch_size=5
val_images = 'drive/My Drive/dataset1/images_prepped_test/' 
val_annotations = 'drive/My Drive/dataset1/annotations_prepped_test/'
val_gen = image_segmentation_generator(
        val_images, val_annotations,  val_batch_size,
        n_classes, input_height, input_width, output_height, output_width)

init = tf.global_variables_initializer()
global_step = tf.train.get_or_create_global_step()

with tf.Session() as sess:
    sess.run(init)
    try:
      history = model.fit_generator(train_gen, epochs=epochs,
                         steps_per_epoch = steps_per_epoch, 
                         validation_data=val_gen, validation_steps=50, callbacks=cks, shuffle=False)
    finally:
      model.save('drive/My Drive/deeplabv3_ep10.h5')

def predict(model, path):
  # Generates labels using most basic setup.  Supports various image sizes.  Returns image labels in same format
  # as original image.  Normalization matches MobileNetV2

  trained_image_width=512 
  mean_subtraction_value=127.5
  image = np.array(Image.open(path))
  plt.imshow(image),plt.show()
  # resize to max dimension of images from training dataset
  w, h, _ = image.shape
  ratio = float(trained_image_width) / np.max([w, h])
  resized_image = np.array(Image.fromarray(image.astype('uint8')).resize((int(ratio * h), int(ratio * w))))

  # apply normalization for trained dataset images
  resized_image = (resized_image / mean_subtraction_value) - 1.

  # pad array to square image to match training images
  pad_x = int(trained_image_width - resized_image.shape[0])
  pad_y = int(trained_image_width - resized_image.shape[1])
  resized_image = np.pad(resized_image, ((0, pad_x), (0, pad_y), (0, 0)), mode='constant')

  # make prediction
  res = model.predict(np.expand_dims(resized_image, 0))
  labels = np.argmax(res.squeeze(), -1)

  # remove padding and resize back to original image
  if pad_x > 0:
      labels = labels[:-pad_x]
  if pad_y > 0:
      labels = labels[:, :-pad_y]
  labels = cv2.resize(labels, (512, 512), interpolation=cv2.INTER_NEAREST)
  return labels

path = '/content/drive/My Drive/tmp/voc_jpeg/6indexmap.jpg'
labels = predict(model, path)
plt.imshow(labels),plt.show()